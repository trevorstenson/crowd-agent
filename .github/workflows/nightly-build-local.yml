name: Nightly Build (Local LLM)

on:
  schedule:
    - cron: '30 0 * * *'  # 00:30 UTC — 30 min after Anthropic build to avoid racing
  workflow_dispatch:
    inputs:
      model:
        description: 'Ollama model to use'
        required: false
        default: 'qwen2.5:7b'

permissions:
  contents: write
  issues: write
  pull-requests: write

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - name: Generate app token
        id: app-token
        uses: actions/create-github-app-token@v1
        with:
          app-id: ${{ secrets.APP_ID }}
          private-key: ${{ secrets.APP_PRIVATE_KEY }}

      - uses: actions/checkout@v4
        with:
          ref: local-agent

      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Install Ollama
        run: curl -fsSL https://ollama.com/install.sh | sh

      - name: Start Ollama server
        run: |
          ollama serve &
          # Wait for Ollama to be ready
          for i in $(seq 1 30); do
            if curl -sf http://localhost:11434/api/tags > /dev/null 2>&1; then
              echo "Ollama is ready"
              break
            fi
            echo "Waiting for Ollama... ($i/30)"
            sleep 2
          done

      - name: Pull model
        run: ollama pull ${{ github.event.inputs.model || 'qwen2.5:7b' }}

      - name: Smoke test inference
        run: |
          curl -sf http://localhost:11434/v1/chat/completions \
            -H "Content-Type: application/json" \
            -d '{"model": "${{ github.event.inputs.model || 'qwen2.5:7b' }}", "messages": [{"role": "user", "content": "Say hello in one word."}], "max_tokens": 10}' \
            | python -c "import sys, json; r = json.load(sys.stdin); print('Smoke test passed:', r['choices'][0]['message']['content'])"

      - name: Run agent
        env:
          LLM_PROVIDER: ollama
          OLLAMA_MODEL: ${{ github.event.inputs.model || 'qwen2.5:7b' }}
          GH_PAT: ${{ steps.app-token.outputs.token }}
          BOT_LOGIN: crowd-agent-bot[bot]
          REPO_OWNER: ${{ github.repository_owner }}
          REPO_NAME: ${{ github.event.repository.name }}
          TWITTER_DRY_RUN: 'true'
        run: python agent/main.py

      - name: Report failure
        if: failure()
        env:
          GITHUB_TOKEN: ${{ steps.app-token.outputs.token }}
        run: |
          gh issue create \
            --title "Local LLM build failure — $(date -u +%Y-%m-%d)" \
            --body "The nightly local-LLM agent build failed. Check the [workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) for details." \
            --label "bug"
